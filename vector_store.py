# -*- coding: utf-8 -*-
"""vector_store.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GSxs1yns7FyNI_gWfPaTKgLsTaUImwbx
"""

from son import data


import pandas as pd
import numpy as np
import json

data = data()

def data_loader():

  #sample_data = pd.read_csv('sample_10_final.csv')
  sample_data = data

  image_list = sample_data['image_path'].tolist()

  sample_10_final = sample_data[['U_id','Case.Case Diagnosis', 'Case.Title','Topic.Category', 'Topic.Disease Discussion',
       'Topic.Title', 'Type', 'Location', 'Location Category',
       'Description.ACR Codes', 'Description.Age', 'Description.Caption',
       'Description.Modality', 'Description.Sex']]

  sample_10_json_str = list(sample_10_final.copy().apply(lambda x: x.to_json(), axis=1))

  return image_list, sample_10_json_str

#image_list, sample_10_json_str = data_loader()
#json_to_clean_text = sample_10_json_str

def embeddings(json_list, text_list, image_list):

  # Load data
  inputs = {
    ModalityType.TEXT: data.load_and_transform_text(json_list, device),
    ModalityType.VISION: data.load_and_transform_vision_data(image_list, device),
  }

  with torch.no_grad():
    embeddings = model(inputs)

  # Assuming embeddings is the output dictionary from your code
  # Reshape text embeddings
  text_embeddings = embeddings['text'].numpy()
  text_embeddings = text_embeddings.reshape(-1, text_embeddings.shape[-1])
  # Reshape vision embeddings
  vision_embeddings = embeddings['vision'].numpy()
  vision_embeddings = vision_embeddings.reshape(-1, vision_embeddings.shape[-1])

  return text_embeddings, vision_embeddings

#text_embeddings, vision_embeddings = embeddings(sample_10_json_str, json_to_clean_text, image_list)



def vector_store(text_embeddings, vision_embeddings, json_to_clean_text, image_list):

  try:
    pc.delete_index("quickstart")
  except:
    pass

  pc.create_index(
    name="quickstart",
    dimension=text_embeddings.shape[1], # Replace with your model dimensions
    metric="cosine", # Replace with your model metric
    spec=ServerlessSpec(
        cloud="aws",
        region="us-east-1"
    )
  )

  index = pc.Index("quickstart")

  for i, (text_embeddings, vision_embeddings, image, text) in enumerate(zip(text_embeddings, vision_embeddings, image_list, json_to_clean_text)):
      index.upsert([
          (f"embedding_{i}_text", text_embeddings, {"type": "text", "Image": image, "Text": text}),
          (f"embedding_{i}_vision", vision_embeddings, {"type": "image", "Image": image, "Text": text})
      ])

#vector_store(text_embeddings, vision_embeddings, json_to_clean_text, image_list)